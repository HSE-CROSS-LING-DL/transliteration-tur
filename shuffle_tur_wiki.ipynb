{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "shuffle tur wiki.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oserikov/transliteration-tur/blob/master/shuffle_tur_wiki.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjIi_aZiKs_t",
        "colab_type": "text"
      },
      "source": [
        "#### предварительные установки\n",
        "\n",
        "заканчиваются появлением папки `/content/tur-wikis`, скопированной из гуглпапки DeepNLP Cross-Lingual Morphological Analysis, в которой лежат разные наши вики."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAoUlkycApx7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "a65d1da5-a509-4ab5-aa9c-179159da648c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMZVvl8qAxyF",
        "colab_type": "text"
      },
      "source": [
        "ссылка на гуглпапку с архивом с вики:\n",
        "https://drive.google.com/drive/folders/12S8mx9W8O1jKk5g81xMsgjEULyRivbsn?usp=sharing\n",
        "\n",
        "**добавьте её в свой гуглдиск в корень**, чтобы работало (я там ниже делаю `!cp -R /content/drive/My\\ Drive/DeepNLP\\ Cross-Lingual\\ Morphological\\ Analysis/tur-wikis .`) или переправьте код на правильный для вас."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxqnVEbnAs53",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp -R /content/drive/My\\ Drive/DeepNLP\\ Cross-Lingual\\ Morphological\\ Analysis/tur-wikis ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEkZfEeKJ6P3",
        "colab_type": "text"
      },
      "source": [
        "## настройки"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-9GNYQuG_Ze",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# настраиваемые переменные:\n",
        "# какие языки добавить в перемешанную выборку\n",
        "languages = ('bak', 'kaz', 'kir', 'tat', 'tur')  #, 'crh', 'krc') \n",
        "# сколько предложений брать из каждого языка\n",
        "language_rows_num = 2000\n",
        "\n",
        "\n",
        "\n",
        "# глобальные переменные, использованные в логике \n",
        "# их менять не нужно\n",
        "normalized_file_extension = \"txt_norm\"\n",
        "normalized_wikis_dir = 'tur-wikis'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FU1Da2vyGz88",
        "colab_type": "text"
      },
      "source": [
        "## составляем выборку обучающих предложений"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTo9Sfj2G5oR",
        "colab_type": "text"
      },
      "source": [
        "### отфильтровываем \"плохие\" предложения\n",
        "`good_line()` будет говорить, \"хорошая\" ли строка"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIQHaUuJG9ve",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def good_line(line) -> bool:\n",
        "    return line.strip() and len(line) > 40"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0EeMCiVBSvr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "cbcfd5d0-c752-46aa-fa3f-4cafe04cc5df"
      },
      "source": [
        "for language in languages:\n",
        "    !echo \"$(date) BEFORE filter out bad sentences for {language}\"\n",
        "    \n",
        "    src_f = open(f\"{normalized_wikis_dir}/{language}.{normalized_file_extension}\", 'r', encoding=\"utf-8\")\n",
        "    tgt_f = open(f\"{normalized_wikis_dir}/{language}.no_headers\", 'w', encoding=\"utf-8\")\n",
        "    \n",
        "    prev_line_was_empty = True\n",
        "    for line in src_f:\n",
        "        # filter out all the *bad* lines and article titles\n",
        "        if not prev_line_was_empty and good_line(line):\n",
        "            print(line, file=tgt_f, end='')\n",
        "\n",
        "        prev_line_was_empty = not bool(line.strip())\n",
        "    \n",
        "    src_f.close()\n",
        "    tgt_f.close()\n",
        "\n",
        "    !echo \"$(date) AFTER filter out bad sentences for {language}\""
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Nov 30 02:46:28 UTC 2019 BEFORE filter out bad sentences for bak\n",
            "Sat Nov 30 02:46:31 UTC 2019 AFTER filter out bad sentences for bak\n",
            "Sat Nov 30 02:46:33 UTC 2019 BEFORE filter out bad sentences for kaz\n",
            "Sat Nov 30 02:46:39 UTC 2019 AFTER filter out bad sentences for kaz\n",
            "Sat Nov 30 02:46:41 UTC 2019 BEFORE filter out bad sentences for kir\n",
            "Sat Nov 30 02:46:43 UTC 2019 AFTER filter out bad sentences for kir\n",
            "Sat Nov 30 02:46:45 UTC 2019 BEFORE filter out bad sentences for tat\n",
            "Sat Nov 30 02:46:48 UTC 2019 AFTER filter out bad sentences for tat\n",
            "Sat Nov 30 02:46:51 UTC 2019 BEFORE filter out bad sentences for tur\n",
            "Sat Nov 30 02:47:03 UTC 2019 AFTER filter out bad sentences for tur\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVZpIpA9HO5W",
        "colab_type": "text"
      },
      "source": [
        "### шафлим полученные хорошие предложения в нужном кол-ве"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFDAM4USHTSl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "70c187b3-165f-419d-f002-daf9f1b68c5e"
      },
      "source": [
        "# выберем language_rows_num случайных хороших предложений из каждого языка\n",
        "# запишем их в pre_shuffled_data.tsv\n",
        "\n",
        "!rm pre_shuffled_data.tsv\n",
        "for language in languages:\n",
        "    !shuf -n {language_rows_num} \\\n",
        "     {normalized_wikis_dir}/{language}.no_headers \\\n",
        "    | sed -e \"s|^|{language}\\t|\" \\\n",
        "    >> pre_shuffled_data.tsv\n",
        "\n",
        "\n",
        "# перемешаем pre_shuffled_data.tsv\n",
        "# запишем результат в shuffled_data.tsv\n",
        "!shuf pre_shuffled_data.tsv > shuffled_data.tsv"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'pre_shuffled_data.tsv': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2xH0dJWJRGw",
        "colab_type": "text"
      },
      "source": [
        "## посмотрим, что получилось"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xt805g7_ENHt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "20d62bdb-9fa1-4866-ff34-edc0ce9c5839"
      },
      "source": [
        "!head shuffled_data.tsv"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kir\tКалкы - 4289 киши(2013-ж.). . Аянты - 10,01 км2. Мамлекет ичинде бекитилген расмий коду — \"08 1 17 025\". Мэр — Лотар Шобер.\n",
            "tat\tРусия дәүләт су реестры мәгълүматы буенча елга Түбән Об су бассейны округында урнашкан, су хуҗалыгы участогы — Об елгасы Иртеш елгасы кушылган урыннан Төньяк Сосва елгасы кушылган урынына кадәр. Кече елга бассейны — Об кушылдыклары бассейны, Иртештән Төньяк Сосьва тамагына кадәр, елга бассейны — (Түбән) Об, Иртеш кушылганга кадәр.\n",
            "tur\tТахтабаş, Ордu илинин Фатса илçесине баğлы бир махалледир.\n",
            "kir\tАлагушов, Балбай. Кыргыз музыкасы: Энциклопедиялык окуу куралы / Башкы редактору Үсөн Асанов. – Бишкек: Мамлекеттик тил жана энциклопедия борбору, 2004. – 400 бет. -ЫСБН 9967-14-016-X.\n",
            "bak\tДәүерҙең ниндәй вақыт арауығын биләүенә қарата берҙәм генә фекер юқ. Қайһы бер тарихсылар уның башын XВЫЫ быуат аҙағына, икенселәре XВЫЫЫ быуат уртаһына бәйләй. XВЫЫ быуатта рационализм нигеҙҙәрен үҙенең «Метод тураһында фекер йөрөтөү» тигән хеҙмәтендә Декарт һала (1637). Мәғрифәтселек осоро аҙағын Вольтерҙың вафаты (1778) йәки Наполеон һуғыштары башланыу (1800—1815) менән бәйләйҙәр. Шул уқ вақытта Мәғрифәтселек дәүере сиктәрен ике инқилап — Англиялағы «Данлы революция» (1688) һәм Бөйөк француз революцияһы (1789) — даталарына беркетеү ҙә бар.\n",
            "bak\t1939 йылда − 40 кеше, 1961 йылда — 210 кеше, 1989 йылда — 120 кеше, 2002 йылда — 53 кеше, 2010 йылда — 19 кеше йәшәй.\n",
            "kaz\tТышқанның бір қолмен ұстауға арналған, жайпақ табанды қаптамасы, үстінде бір немесе бірнеше батырмасы, түп жағында көп бағытты бергіш құрылғысы (әдетте кішкентай шар) және оны компьютерге жалғайтын сымы болады.\n",
            "kir\tБул бөлүм улам толукталмакчы. Айрым чыгармалар тизмеси ушул шилтемеде. \n",
            "kaz\tРесей мемлекеттік су тізілімінің мәліметі бойынша Двинск-Печорск су алабы өңіріне жатады, өзеннің сушаруашылық бөлігі — Печора өзені су өлшейтін постқа Усть-Цильма және сағасына дейін. Өзен саласы — Усаға қосылу құйылысынан төмен Печора тармағының су алаптары, өзен алабы — Печора.\n",
            "tat\tПочта индексы — 429311. Гомумрусия административ-территориаль объектлары бүленеше классификаторы коды - 97216836002. Дәүләт идарәсе секторы операцияләре классификациясе коды - 2100700002100.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phbeAS9yJZlt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "fc3ebae8-c81c-4fe0-923e-1b7e933985c2"
      },
      "source": [
        "for language in languages:\n",
        "    !echo \"there are $(grep ^{language} shuffled_data.tsv | wc -l ) samples of language {language}\""
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "there are 2000 samples of language bak\n",
            "there are 2000 samples of language kaz\n",
            "there are 2000 samples of language kir\n",
            "there are 2000 samples of language tat\n",
            "there are 2000 samples of language tur\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}